---
title: "Final Report"
subtitle: |
  | Final Project 
  | Data Science 2 with R (STAT 301-2)
author: "Chiemela Onuoha"
pagetitle: "FR Chiemela Onuoha"
date: "today"

format:
  html:
    toc: true
    toc-depth: 4
    toc-location: left
    embed-resources: true
    link-external-newwindow: true

execute:
  warning: false

from: markdown+emoji
reference-location: margin
citation-location: margin
---


```{r}
#| echo: false
#| label: load-packages-data

library(tidyverse)
library(tidymodels)
library(DT)
library(here)

# resolve conflicts
tidymodels_prefer()


# load in data ----
movies <- read_csv("data/imdb_movies.csv")
# read in data ----
movies_data <- read_csv("data/movies_clean.csv")


```

::: {.callout-tip icon=false}

## Github Repo Link

[Chiemela's Github (chiemelaonu)](https://github.com/stat301-2-2025-winter/final-project-2-chiemelaonu.git)

:::

## Introduction
The objective of this report is to present findings of predictive modeling done on a movies dataset. I would like to see how well a movies' revenue can be predicted using other features of the movie/data.
<br>  
These predictions are useful because having an accurate prediction model for movie revenue could be highly valuable for investors and filmmakers because it would help estimate a filmâ€™s financial success before release. That would allow for better budget allocation, and even optimize marketing strategies.

## Data Overview
Below is a table showing the attributes of our movies dataset, like the column type and number of missing variables. With this table, we see that there are very few missing values, and those that are missing are present in the genre and crew columns. The main purpose of this check is to see any missingness in the target variable, which is not present in this data. 
```{r}
#| label: tbl-missing
#| tbl-cap: "Skim of Missing Data"
#| echo: false

# missingness check ----
movies |>
  skimr::skim_without_charts() |>
  knitr::kable()

```

The table below provides a more concise skimming of the data, telling us that we have just under 10,200 observations, 12 columns, 126 rows with missing values.
```{r}
#| label: tbl-eda
#| tbl-cap: "Dataset Summary"
#| echo: false

# calculate values
missing_rows <- sum(!complete.cases(movies))
num_rows <- nrow(movies)
num_cols <- ncol(movies)
target_missing <- sum(!complete.cases(movies$revenue))

# create a table
summary_table <- tibble(
  Metric = c("Rows with Missing Values", "Number of Observations", "Number of Variables", "Number of Missing Target Variable Observations (`revenue`)"),
  Value = c(missing_rows, num_rows, num_cols, target_missing)
) |> knitr::kable()


summary_table
```

::: {#fig-price-dists layout-ncol=2}

![revenue on Original Scale ($)](figures/target_eda.png){#fig-revenue-orig}

![revenue Transformed with Yeo-Johnson](figures/target_eda_2.png){#fig-revenue-yj}

:::
On the left, we have the original distribution of the target variable, revenue, visualized with a density plot and box plot. The original values were heavily skewed right, so it was apparent a transformation of revenue was needed. After experimenting with log, Yeo-Johnson, square root, and Box-Cox transformations, I settled on a Yeo-Johnson transformation to make the values more evenly distributed.^[A lambda value of 0.25 was used] The density and box plot on the right shows those values post-transformation. 

### Data Wrangling
The movies dataset initially had 12 columns and I was only able to extract 3 predictors for my models, but I have been able to conduct more manipulation of the data to allow for more usable predictors in my models. 
```{r}
#| label: tbl-modified-data
#| tbl-cap: "Movies Data with Added Columns"
#| echo: false

movies_data |>
  glimpse()
```

In the table above, you can see that I added a column called `num_genres` that has the counts of the genres for each movie. I added columns `negative`, `positive`, and `overall_sentiment` that uses the `tidytext` package to parse the `overview` column and note which words are positive or negative. The `positive` and `negative` columns hold the counts of those kinds of words present in each observation, and the `overall_sentiment` column gives the overall sentiment: Negative, Positive, or Neutral, depending on how many of each kind was counted. Some of the observations had NA for these columns, but I imputed those values with the mean (for the `negative` and `positive` columns) and the mode (for the `overall_sentiment` column). Lastly, I added a column called `num_crew` that counts the number of crew members listed for each movie. These new columns will serve as better features for my model, in the hopes of creating more accurate and meaningful predictions.

## Methods

### Data Splitting
I decided on a split proportion of 80-20 because it gives an optimal amount of data in the testing and training sets. I also used the default number of strata and stratified by our target variable, yeo_revenue (the Yeo-Johnson transformed revenue).

#### Resampling
I will be using V-fold cross-validation for resampling, with 5 folds (V) and 3 repeats. This method is useful because it ensures that each data point is used for both training and testing, providing a more reliable estimate of model performance.

### Metrics
The metric I used for comparing and selecting a final model is RMSE. RMSE is the Root Mean Squared Error which measures the square root of the average squared differences between the predicted and actual values, providing a way to quantify how much the model's predictions deviate from the true values. I picked RMSE as my metric because it is commonly used in regression modeling and is a relatively simple metric to interpret and explain.



### Model Descriptions
This is a regression problem because the target variable, revenue, is continuous rather than categorical. Since it is a regression problem, I knew I would like to fit/tune a Null/Baseline model, an OLS model, Elastic Net models, a Random Forest Model, a Boosted Trees model, and a K-Nearest Neighbors model.

#### Null/Baseline
A null model is a simple model that based solely on the mean (for regression). It serves as a basic reference to compare the performance of more complex models.  
<br>  
A baseline model is a simple predictive model used as a benchmark. Its use is to set a reasonable lower bound for predictive performance. Comparing against a baseline helps measure whether advanced modeling techniques provide meaningful improvement.


#### OLS
An Ordinary Least Squared (OLS) model is used for when relationships are linear, features are independent, and interpretability is needed. An OLS model captures linear relationships, effect sizes, and predictor significance well, and is a almost always one of the first models to be used in a regression problem. It provides another fairly simple benchmark for our model.

#### Elastic Net
Elastic Net is a regularized regression method that combines Ridge and Lasoo penalties. It stabilizes coefficient estimates like Ridge while also eliminating irrelevant variables like Lasso. Elastic Net is particularly useful when predictors are highly correlated, when there are more features than observations, or when handling noisy or sparse data.  
<br>  
The parameters I will be tuning are mixture and penalty.

#### Random Forest
Random Forest is an ensemble learning method that builds multiple decision trees and averages their predictions to improve accuracy and reduce overfitting. It is ideal for capturing nonlinear relationships and handling high-dimensional data.  
<br> 
The parameters I will be tuning are mtry, and min_n.

#### Boosted Trees
Boosted trees is a method that builds decision trees sequentially, where each tree corrects the errors of the previous one, leading to high predictive accuracy and strong performance on complex datasets. They do well at capturing nonlinear relationships, handling feature importance, and reducing bias, making them ideal for structured data with intricate patterns.  
<br>  
The parameters I will be tuning are min_n, mtry, and learn_rate.

#### K-Nearest Neighbors
K-Nearest Neighbors is a non-parametric model that classifies or predicts values based on the majority vote of nearby data points or their average. It works well for nonlinear relationships.  
<br>  
The parameters I will be tuning are neighbors.

### Recipes
There are 2 recipes defined for each model (or set of models in the case of the Elastic Net models), excluding the Null/Baseline models that use only one recipe. There is each a "basic" recipe and a "complex" recipe used for the models. 

#### Null/Baseline Model Recipe
The first recipe was for the null and baseline models. My first step was to impute the mean of all missing numerical values. I also imputed the mode of the `overall_sentiment` column because of NAs. Next, I used `step_date()` to extract the year and month out of the date column to use as predictors. Lastly, I used `step_dummy()` to one-hot encode the `overall_sentiment` column so that all 3 types of sentiments are captured and used as predictors.  

#### Linear Model Recipes
For my complex Linear model recipe, most of the steps are the same as the null/baseline recipe, except I used `step_interact()` to create an interaction with 2 sets of predictors I feel would work together in this predictive process, and used `step_normalize()` to scale and center the numerical predictors to prevent multicollinearity. I also added a Yeo-Johnson transformation of the `budget_x` column. For my basic Linear model recipe has everything previously stated, except the interactions and the `budget_x` transformation.  

#### Tree Based Model Recipes  
For my basic tree model recipe, I kept the same steps as my basic Linear model recipe. For my complex recipe, I created a new column called `season` that splits up the months into the 4 seasons and used that as a predictor as well.

## Model Building and Selection Results