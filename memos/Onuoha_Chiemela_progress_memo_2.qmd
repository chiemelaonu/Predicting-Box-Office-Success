---
title: "Progress Memo 2"
subtitle: |
  | Final Project 
  | Data Science 2 with R (STAT 301-2)
author: "Chiemela Onuoha"
pagetitle: "PM2 Chiemela Onuoha"
date: "today"

format:
  html:
    toc: true
    toc-depth: 4
    toc-location: left
    embed-resources: true
    link-external-newwindow: true

execute:
  warning: false

from: markdown+emoji
reference-location: margin
citation-location: margin
---


```{r}
#| echo: false
#| label: load-packages-data

library(tidyverse)
library(tidymodels)
library(DT)
library(here)

# resolve conflicts
tidymodels_prefer()

```

::: {.callout-tip icon=false}

## Github Repo Link

[Chiemela's Github (chiemelaonu)](https://github.com/stat301-2-2025-winter/final-project-2-chiemelaonu.git)

:::

## Data source

[Kaggle.com](https://www.kaggle.com/datasets/ashpalsingh1525/imdb-movies-dataset/data)
Data was sourced from Kaggle.com, a site hosting thousands of datasets for the public to use. Accessed February 3rd, 2025^[The Kaggle data was compiled from IMDB.com]

## Analysis Plan
My analysis plan is to split the data with `prop = 0.8` and `strata = yeo_revenue`. I also will be using V-fold cross validation and fitting my models (Null, Baseline, OLS, Lasso, Ridge, Random Forest, Boosted Trees, and KNN) to the resamples. My V-fold cross validation consists of 5 folds and 3 repeats. I will be tuning the models that utilize hyperparameters so that I can use the most suitable hyperparamaters for my data. I currently have my null/baseline recipe, and 2 linear model recipes, and 2 tree model recipes. 

## Recipes
The first recipe was for the null and baseline models. My first step was to impute the mean of all missing numerical values. I also imputed the mode of the `overall_sentiment` column because of NAs. Next, I used `step_date()` to extract the year and month out of the date column to use as predictors. Lastly, I used `step_dummy()` to one-hot encode the `overall_sentiment` column so that all 3 types of sentiments are captured and used as predictors.  
<br>  
For my complex Linear model recipe, most of the steps are the same as the null/baseline recipe, except I used `step_interact()` to create an interaction with 2 sets of predictors I feel would work together in this predictive process, and used `step_normalize()` to scale and center the numerical predictors to prevent multicollinearity. I also added a Yeo-Johnson transformation of the `budget_x` column. For my basic Linear model recipe has everything previously stated, except the interactions and the `budget_x` transformation.  
<br>  
For my basic tree model recipe, I kept the same steps as my basic Linear model recipe. For my complex recipe, I created a new column called `season` that splits up the months into the 4 seasons and used that as a predictor as well.

### Updates on Data Since Memo 1
I initially only had 3 predictors for my models, but I have been able to conduct more manipulation of the data to allow for more usable predictors in my models. I added a column called `num_genres` that has the counts of the genres for each movie. I added columns `negative`, `positive`, and `overall_sentiment` that uses the `tidytext` package to parse the `overview` column and note which words are positive or negative. The `positive` and `negative` columns hold the counts of those kinds of words present in each observation, and the `overall_sentiment` column gives the overall sentiment: Negative, Positive, or Neutral, depending on how many of each kind was counted. Some of the observations had NA for these columns, but I imputed those values with the mean (for the `negative` and `positive` columns) and the mode (for the `overall_sentiment` column). Lastly, I added a column called `num_crew` that counts the number of crew members listed for each movie. These new columns will serve as better features for my model, in the hopes of creating more accurate and meaningful predictions.

### Fitted Results
```{r}
#| label: load-basic-fits
#| echo: false
#| results: hide

# load in training data ----
list.files(
  here("results/"),
  pattern = ".rda",
  full.names = TRUE
) |>
  map(load, envir = .GlobalEnv)
```


```{r}
#| label: fitted-results
#| echo: false


# examine results
model_results <-
  as_workflow_set(
    lm = lm_basic_fit,
    null = null_results,
    baseline = baseline_results
  ) 


basic_fits_table <- model_results |>
  collect_metrics() |>
  filter(.metric == "rmse") |>
  slice_min(mean, by = wflow_id) |>
  arrange(mean) |>
  select(
    `Model Name` = wflow_id,          
    `Metric Type` = .metric,          
    `Mean RMSE` = mean,               
    `Standard Error` = std_err,
    n              
  ) |> knitr::kable()

basic_fits_table
```
This is a table with the Null, Baseline, and Basic Linear Model fit. The basic Linear model has the lowest RMSE of 119.8 and a standard error of 0.444. When incorporating the error, the RMSE is 120.24, which is slightly higher than the Null model RMSE, but still very close, so I would label the Null and Basic Linear model fit as fairly equal. The Baseline model does much worse, with an RMSE of 174.66 and a standard error of 0.394. 

### Moving Forward
My data has been split and so far and all recipes have been defined. I have defined and fit/tuned all of my models so far and will be continuing with assessing the RMSEs. Then I will train that model to the training set and predict on the testing set and assess that final model. As of right now, I do not see an issues or areas of concern, but will be stay vigilant in case any appear. I feel that I am doing well time-wise and will continue to make consistent progress so that the final report and executive summary are good quality.


