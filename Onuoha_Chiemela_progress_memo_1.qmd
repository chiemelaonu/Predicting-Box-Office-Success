---
title: "Progress Memo 1"
subtitle: |
  | Final Project 
  | Data Science 2 with R (STAT 301-2)
author: "Chiemela Onuoha"
pagetitle: "PM1 Chiemela Onuoha"
date: "January 25, 2025"

format:
  html:
    toc: true
    toc-depth: 4
    toc-location: left
    embed-resources: true
    link-external-newwindow: true

execute:
  warning: false

from: markdown+emoji
reference-location: margin
citation-location: margin
---


```{r}
#| echo: false
#| label: load-packages-data
library(tidyverse)
movies <- read_csv("data/final_dataset.csv")

```

::: {.callout-tip icon=false}

## Github Repo Link

[Chiemela's Github (chiemelaonu)](https://github.com/stat301-2-2025-winter/final-project-2-chiemelaonu.git)

:::

## Data source

[Kaggle.com](https://www.kaggle.com/datasets/raedaddala/top-500-600-movies-of-each-year-from-1960-to-2024/code)
Data was sourced from Kaggle.com, a site hosting thousands of datasets for the public to use. Accessed January 24th 2025


## Prediction Problem
The objective of this prediction model is to forecast the worldwide gross earnings of a movie based on various features such as its budget, cast, director, genre, duration, and other available data. Specifically, the research question could be framed as: "Given a set of characteristics about a movie, can we accurately predict its total gross earnings worldwide?" This is a regression problem because the target variable, `grossWorldWide`, is a continuous numeric variable representing the total revenue generated by a movie worldwide.  
<br>
A prediction model for worldwide gross earnings can be highly valuable for stakeholders in the film industry, such as producers, investors, and distributors. It can provide insights into expected profitability and help guide decisions on budget allocation, marketing strategies, and distribution plans.  <br>  
I am in interested in using this data because movies are fun and a form of expression, so analyzing the data and creating a predictive model with it would be a genuinely intriguing task, making the work more enjoyable.

## Data Quality Check


The data has 23 variables, with 33,600 observations. It has 14 categorical variables, and 9 numerical variables.


```{r}
#| label: tbl-summary
#| tbl-cap: "Dataset Summary"
#| echo: false


# calculate values
missing_rows <- sum(!complete.cases(movies))
num_rows <- nrow(movies)
num_cols <- ncol(movies)

# create a table
summary <- data.frame(
  Metric = c("Rows with Missing Values", "Number of Observations", "Number of Variables"),
  Value = c(missing_rows, num_rows, num_cols)
)

# display as a table
knitr::kable(summary, caption = "Dataset Summary")

```


### Missingness 

```{r}
#| label: tbl-missing
#| tbl-cap: "Dataset Missingness"
#| echo: false

missing_values <- colSums(is.na(movies))

# Filter columns with missing values (those with more than 0 missing values)
missing_summary <- data.frame(
  Column = names(missing_values),
  Missing_Values = missing_values
)

# Filter rows where there are missing values
missing_summary <- missing_summary[missing_summary$Missing_Values > 0, ]

# Display the table with knitr
knitr::kable(missing_summary, caption = "Columns with Missing Values")
```



## Target Variable Analysis

::: {#fig-price-dists layout-ncol=2}

![Gross Profit on Original Scale ($)](figures/graphic_1.png){#fig-profit-orig}

![Gross Profit Transformed to log 10 Scale](figures/graphic_2.png){#fig-profit-log10}

Inspecting target distribution `grossWorldWide` on original scale and on a log 10 transformation scale.
:::
The target variable is heavily skewed right. Seeing this, a log transformation is helpful because it makes the distribution more symmetrical.
Symmetrical distributions are balanced around the mean, so the model doesn't get influenced by outliers or skewed data. There are also substantial amount of missing values in the data set, so removing those missing observations allows for a more comprehensive model on the data. 